import os
import json
import pickle
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# === è·¯å¾„é…ç½® ===
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(BASE_DIR, "all-MiniLM-L6-v2")  # æœ¬åœ°æ¨¡å‹
DATA_PATH = os.path.join(BASE_DIR, "knowledge_base_text.jsonl")  # ä½ çš„çŸ¥è¯†åº“
INDEX_PATH = os.path.join(BASE_DIR, "rag_index.faiss")  # è¾“å‡º FAISS ç´¢å¼•
TEXTS_PATH = os.path.join(BASE_DIR, "rag_texts.pkl")  # ä¿å­˜æ–‡æœ¬æ˜ å°„

# === åŠ è½½æ¨¡å‹ ===
print("ğŸ”¹ Loading local embedding model...")
model = SentenceTransformer(MODEL_PATH)
print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")

# === åŠ è½½çŸ¥è¯†åº“æ•°æ® ===
print(f"ğŸ”¹ Loading dataset: {DATA_PATH}")
texts = []
with open(DATA_PATH, "r", encoding="utf-8") as f:
    for line in f:
        line = line.strip()
        if not line:
            continue
        try:
            obj = json.loads(line)
            if "text" in obj:
                texts.append(obj["text"])
        except Exception as e:
            print("âŒ è§£æé”™è¯¯:", e)

print(f"âœ… å…±åŠ è½½æ–‡æœ¬ {len(texts)} æ¡")

# === ç”ŸæˆåµŒå…¥å‘é‡ ===
print("ğŸ”¹ Encoding texts...")
embeddings = []
for text in tqdm(texts, desc="Encoding"):
    emb = model.encode(text, show_progress_bar=False, normalize_embeddings=True)
    embeddings.append(emb)

embeddings = np.array(embeddings).astype("float32")
print(f"âœ… å‘é‡ç”Ÿæˆå®Œæˆï¼Œå½¢çŠ¶: {embeddings.shape}")

# === æ„å»º FAISS ç´¢å¼• ===
print("ğŸ”¹ Building FAISS index...")
index = faiss.IndexFlatIP(embeddings.shape[1])  # ä½¿ç”¨å†…ç§¯ï¼ˆIPï¼‰åŒ¹é…
index.add(embeddings)
faiss.write_index(index, INDEX_PATH)
print(f"âœ… FAISS ç´¢å¼•å·²ä¿å­˜è‡³: {INDEX_PATH}")

# === ä¿å­˜æ–‡æœ¬æ˜ å°„ ===
with open(TEXTS_PATH, "wb") as f:
    pickle.dump(texts, f)
print(f"âœ… æ–‡æœ¬æ˜ å°„å·²ä¿å­˜è‡³: {TEXTS_PATH}")

print("\nğŸ‰ ç´¢å¼•æ„å»ºå®Œæˆï¼Œå¯ä»¥ç›´æ¥ç”¨äº RAG æ£€ç´¢ï¼")
