# scan_lora_target_modules.py
import torch
from transformers import AutoModelForCausalLM

BASE_MODEL = "/root/Agent/baichuan-7b"  # æ›¿æ¢æˆä½ çš„æ¨¡å‹è·¯å¾„

print(f"ğŸ”¹ Loading base model from {BASE_MODEL}...")
model = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL,
    device_map="auto",
    load_in_4bit=True,  # æˆ– Falseï¼Œå¦‚æœä½ åªæƒ³æ‰«ææ¨¡å—
    trust_remote_code=True
)

print("ğŸ”¹ Scanning for Linear layers (potential LoRA target modules)...\n")
linear_modules = []

for name, module in model.named_modules():
    if isinstance(module, torch.nn.Linear):
        linear_modules.append(name)
        print(name)

print("\nâœ… Scan complete!")
print(f"Found {len(linear_modules)} Linear layers.")
print("\nğŸ’¡ Example LoRA target_modules could be one or more of these:")
print(linear_modules[:10], "...")  # åªæ˜¾ç¤ºå‰10ä¸ªç¤ºä¾‹
