import os
import json

base_dir = "/root/Agent/all-MiniLM-L6-v2"
transformer_dir = os.path.join(base_dir, "0_Transformer")
pooling_dir = os.path.join(base_dir, "1_Pooling")
modules_json = os.path.join(base_dir, "modules.json")

# âœ… åªä¿ç•™å…³é”®æ–‡ä»¶ï¼ˆTransformer æ¨¡å—éœ€è¦çš„ï¼‰
keep_files = {
    "config.json",
    "pytorch_model.bin",
    "vocab.txt",
    "tokenizer.json",
    "tokenizer_config.json",
    "special_tokens_map.json"
}

# æ¸…ç†å¤šä½™æ–‡ä»¶
for f in os.listdir(transformer_dir):
    if f not in keep_files:
        os.remove(os.path.join(transformer_dir, f))
        print(f"ğŸ—‘ï¸ å·²åˆ é™¤å¤šä½™æ–‡ä»¶: {f}")

# âœ… é‡å»º modules.jsonï¼ˆé˜²æ­¢æ—§æ–‡ä»¶æ®‹ç•™ï¼‰
modules_config = [
    {
        "idx": 0,
        "name": "0_Transformer",
        "path": "0_Transformer",
        "type": "sentence_transformers.models.Transformer"
    },
    {
        "idx": 1,
        "name": "1_Pooling",
        "path": "1_Pooling",
        "type": "sentence_transformers.models.Pooling"
    }
]
with open(modules_json, "w", encoding="utf-8") as f:
    json.dump(modules_config, f, ensure_ascii=False, indent=2)

print("âœ… æ¸…ç†å®Œæˆï¼Œæ¨¡å—æ–‡ä»¶å·²æ›´æ–°")

# æ‰“å°æœ€ç»ˆç›®å½•ç»“æ„ï¼ˆå¯è§†åŒ–æ£€æŸ¥ï¼‰
for root, dirs, files in os.walk(base_dir):
    level = root.replace(base_dir, '').count(os.sep)
    indent = ' ' * 2 * level
    print(f"{indent}{os.path.basename(root)}/")
    subindent = ' ' * 2 * (level + 1)
    for f in files:
        print(f"{subindent}{f}")

print("\nâœ… ç°åœ¨é‡æ–°è¿è¡Œ:")
print("from sentence_transformers import SentenceTransformer")
print("model = SentenceTransformer('./Agent/all-MiniLM-L6-v2')")
