query,mode,prediction,BLEU,ROUGE-L,EM
中国的首都是哪里？,RAG,"已知资料：中国的首都是北京。
问题：中国的首都是哪里？
请基于资料简洁回答。































































































































",0.0,0.0,0.0
FAISS 是什么？,RAG,"已知资料：FAISS 是一个高效的相似度搜索库。
问题：FAISS 是什么？
请基于资料简洁回答。
FAISS (Fast and Accurate Inverted Space Search) 是一个高效的相似度搜索库。
FAISS 是什么？
FAISS 是一个高效的相似度搜索库。它在单个 GPU 上提供超过 100 万亿次的单向搜索。FAISS 基于哈希函数，并使用一种称为“内插”的低秩近似技术来高效地实现高精度搜索。内插是一种稀疏近似方法，它能够在不丢失精度的情况下将非线性函数映射到线性空间。FAISS 使用稀疏矩",0.009849349468888718,0.125,0.0
BERT 是谁提出的？,RAG,"已知资料：BERT 是谷歌提出的预训练语言模型。
问题：BERT 是谁提出的？
请基于资料简洁回答。
百度百科：
[[Bidirectional Encoder Representations from Transformers]] (BERT) is a natural language processing (NLP) model developed by a research team at Google Brain, the AI research team of Google. It is an unsupervised pre-training method for sequence-to-sequence models. The model is a multi-layer bidirectional transformer encoder, and it has achieved state-of-the-art results on various NLP benchmarks, including question answering, text classification, text summarization, and text generation.
BERT 是谷",0.003000012090121809,0.026666666666666665,0.0
中国的首都是哪里？,NoRAG,"问题：中国的首都是哪里？
请直接回答。
北京
北京
北京
北京
北京",0.0,0.0,0.0
FAISS 是什么？,NoRAG,"问题：FAISS 是什么？
请直接回答。FAISS 是什么？FAISS 是一个开源的分布式数据库，它将 GPU 用于高性能查询。FAISS 的主要用例包括机器学习中的模型训练和模型评估，以及数据库中的查询。FAISS 使用基于矩阵的计算来减少查询的时间复杂度，从而实现高性能。FAISS 的主要功能包括：FAISS 的主要优点包括：FAISS 的主要缺点包括：FAISS 的使用场景包括：FAISS 的使用场景包括：FAISS 的使用场景包括：FAISS 的使用场景包括：FAISS 的使用场景包括：FAISS 的使用",0.0,0.125,0.0
BERT 是谁提出的？,NoRAG,"问题：BERT 是谁提出的？
请直接回答。请看我的理解：BERT 是一种 NLP 模型，它可以处理自然语言。BERT 是一种基于 Transformer 的模型，它使用了注意力机制。BERT 可以处理文本，也可以处理图片。BERT 是一种预训练模型，它可以在训练数据集上进行训练。BERT 可以用于各种 NLP 任务，如文本分类、文本生成、文本匹配、问答系统等。",0.0,0.19999999999999998,0.0
